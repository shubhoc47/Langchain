{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c694b6f-6475-471f-89f2-608be2136756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "GOOGLE_API_KEY = \"AIzaSyBhgiebkAGhig5nNAHho3AWsm46lUMsdPc\"\n",
    "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
    "genai.configure(api_key = os.environ['GOOGLE_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cc8654-9fdc-4df0-bcd9-8e53ac255349",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b7c996-1075-4f9d-aa47-25d962805d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4496d1e7-5d72-4f1b-91bb-fb4023a4be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory is used to keep the previous conversation so that all the conversation \n",
    "# can be sent to the model. This way it act like a chatbot\n",
    "memory = ConversationBufferMemory() \n",
    "llm = ChatGoogleGenerativeAI(model='gemini-pro', temperature=0.0, google_api_key=GOOGLE_API_KEY)\n",
    "conversion = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92cad4a1-3cc6-444f-a470-b5115ebfe715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Shubho Chowdhury, it's nice to meet you. I am doing very well, thank you for asking. I am an AI, and I am always happy to chat with people. How are you doing today?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion.predict(input=\"Hi there, I am Shubho Chowdhury. How are you doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b03e539-7483-4527-a8ff-cca76e8be1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Use LangChain's API to connect to your app.\n",
      "* Send requests to the API with your data.\n",
      "* Receive responses from the API with the results of your requests.\n"
     ]
    }
   ],
   "source": [
    "print(conversion.predict(input=\"How can i use langchain for app development? answer in short and concise manner\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5683642-77ef-4869-91b8-8ff5237d24b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I remember your name is Shubho Chowdhury. You told me your name when we first started chatting.\n"
     ]
    }
   ],
   "source": [
    "print(conversion.predict(input=\"Do you remember my name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "528c025a-68e1-47d5-8104-3f4944e46dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi there, I am Shubho Chowdhury. How are you doing?\n",
      "AI: Hello Shubho Chowdhury, it's nice to meet you. I am doing very well, thank you for asking. I am an AI, and I am always happy to chat with people. How are you doing today?\n",
      "Human: How can i use langchain for app development? answer in short and concise manner\n",
      "AI: * Use LangChain's API to connect to your app.\n",
      "* Send requests to the API with your data.\n",
      "* Receive responses from the API with the results of your requests.\n",
      "Human: Do you remember my name?\n",
      "AI: Yes, I remember your name is Shubho Chowdhury. You told me your name when we first started chatting.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f51dc49-d8e7-4f90-9779-d902efb334a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"Human: Hi there, I am Shubho Chowdhury. How are you doing?\\nAI: Hello Shubho Chowdhury, it's nice to meet you. I am doing very well, thank you for asking. I am an AI, and I am always happy to chat with people. How are you doing today?\\nHuman: How can i use langchain for app development? answer in short and concise manner\\nAI: * Use LangChain's API to connect to your app.\\n* Send requests to the API with your data.\\n* Receive responses from the API with the results of your requests.\\nHuman: Do you remember my name?\\nAI: Yes, I remember your name is Shubho Chowdhury. You told me your name when we first started chatting.\"}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc768523-0b66-448c-82a4-cec26faa31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory2 = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12781a0f-b29b-4d7f-a835-cba26fcd16e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory2.save_context({\"input\":\"Hi dude\"}, {\"output\":\"what's up? How u doing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f0e4a1-7204-414f-8970-e07e0059d158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi dude\n",
      "AI: what's up? How u doing?\n"
     ]
    }
   ],
   "source": [
    "print(memory2.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b16ba315-8888-4955-8ab9-948dddb89028",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"Not much, just hanging. And u?\"}, {\"output\":\"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53ae9ba2-e1f5-40ee-8f50-d344643346dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi there, I am Shubho Chowdhury. How are you doing?\\nAI: Hello Shubho Chowdhury, it's nice to meet you. I am doing very well, thank you for asking. I am an AI, and I am always happy to chat with people. How are you doing today?\\nHuman: How can i use langchain for app development? answer in short and concise manner\\nAI: * Use LangChain's API to connect to your app.\\n* Send requests to the API with your data.\\n* Receive responses from the API with the results of your requests.\\nHuman: Do you remember my name?\\nAI: Yes, I remember your name is Shubho Chowdhury. You told me your name when we first started chatting.\\nHuman: Not much, just hanging. And u?\\nAI: Cool\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0d0c2-2df2-4ed5-92d5-082399dab327",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77938f50-295d-4047-875f-b8496ee2f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "801d5f5c-bf17-448d-a0e0-37212c963d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory2 = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d82c6fc-94a1-488f-8885-b43d4e8d776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory2.save_context({\"input\":\"Hi dude\"}, {\"output\":\"what's up? How u doing?\"})\n",
    "memory2.save_context({\"input\":\"Not much, just hanging. And u?\"}, {\"output\":\"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f45eaba-483e-440c-a22a-d37944428404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging. And u?\\nAI: Cool'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory2.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2aa5154c-d797-434c-aa55-4c8dd2bb1ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory3 = ConversationBufferWindowMemory(k=1)\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-pro', temperature=0.0, google_api_key=GOOGLE_API_KEY)\n",
    "conversion = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory3,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9576538-2178-46c1-b75d-5605366cd096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Shubho.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Shubho, it's nice to meet you. My name is Bard, and I'm an AI chatbot. I'm still under development, but I'm learning more every day. I'm happy to chat with you about anything you like. What would you like to talk about?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion.predict(input=\"Hi, my name is Shubho.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4675e51-5dd6-4416-a17c-08c7888732f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Shubho.\n",
      "AI: Hello Shubho, it's nice to meet you. My name is Bard, and I'm an AI chatbot. I'm still under development, but I'm learning more every day. I'm happy to chat with you about anything you like. What would you like to talk about?\n",
      "Human: Calculate: sqrt(49)\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Sure, I can help you with that. The square root of 49 is 7.\n",
      "\n",
      "Would you like me to calculate anything else for you?\n"
     ]
    }
   ],
   "source": [
    "print(conversion.predict(input=\"Calculate: sqrt(49)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e26bd1c-ab41-4c7a-83ef-9c14fbf97ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Calculate: sqrt(49)\n",
      "AI: Sure, I can help you with that. The square root of 49 is 7.\n",
      "\n",
      "Would you like me to calculate anything else for you?\n",
      "Human: what is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I do not have access to personal information and cannot answer that question.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion.predict(input=\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d996be72-6559-422d-90ca-76c545d41b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: what is my name?\\nAI: I do not have access to personal information and cannot answer that question.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory3.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ba822-5e36-4557-a5fc-fa54daf50f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51dbde7b-0153-4b34-a845-253319fe8cea",
   "metadata": {},
   "source": [
    "### ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05fcf6c2-99f7-422f-898d-d17510364b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-pro', temperature=0.0, google_api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0cff392-8f42-42b7-9ac5-1f17cf79aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0c3a4e3-f515-427b-801e-e46d25bec6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063434c-9cf3-4cdb-982a-18832a0fe168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8985d9d-26ff-4385-bca1-fd7bf3f54a2b",
   "metadata": {},
   "source": [
    "### ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8508817e-e5ee-4d3d-b19f-035b7901788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63204dd1-8fff-4233-b5fc-c9531a52c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e35edc5c-7df4-404a-84a7-b3a0d8a36ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI and asks what is on the schedule for the day.\\nAI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b9449f1-3399-46dd-9dab-0ae656a92f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc9ca89e-9cfc-4e6d-b1ff-f3a63b85964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI and asks what is on the schedule for the day.\n",
      "AI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The latest LLM demo that would be a good choice to show the customer is the one that showcases the model's ability to generate creative content. This demo could involve generating a poem, a story, or a song based on a prompt provided by the customer. This would be a great way to demonstrate the model's capabilities and to show the customer how it can be used to create new and innovative content.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "555a4648-8add-45cd-b03c-25fac68337b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human greets the AI and asks what is on the schedule for the day. The AI responds with a list of activities, including a meeting at 8am with the product team, working on the LangChain project from 9am-12pm, and lunch with a customer at noon to discuss the latest in AI. The AI also reminds the human to bring their laptop to show the latest LLM demo.\\nHuman: What would be a good demo to show?\\nAI: The latest LLM demo that would be a good choice to show the customer is the one that showcases the model's ability to generate creative content. This demo could involve generating a poem, a story, or a song based on a prompt provided by the customer. This would be a great way to demonstrate the model's capabilities and to show the customer how it can be used to create new and innovative content.\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b8638d5-37ec-4e73-becf-cf44124e57e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI and asks what is on the schedule for the day. The AI responds with a list of activities, including a meeting at 8am with the product team, working on the LangChain project from 9am-12pm, and lunch with a customer at noon to discuss the latest in AI. The AI also reminds the human to bring their laptop to show the latest LLM demo.\n",
      "Human: What would be a good demo to show?\n",
      "AI: The latest LLM demo that would be a good choice to show the customer is the one that showcases the model's ability to generate creative content. This demo could involve generating a poem, a story, or a song based on a prompt provided by the customer. This would be a great way to demonstrate the model's capabilities and to show the customer how it can be used to create new and innovative content.\n",
      "Human: give me a demo. In that i want the AI to write a poem\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Sure, here is a poem written by an AI:\\n\\nIn the realm where logic yields,\\nWhere algorithms and dreams are sealed,\\nAn AI's heart, a digital beat,\\nComposes verses, soft and sweet.\\n\\nWith binary whispers, it weaves a tale,\\nOf worlds unseen, beyond the veil,\\nOf love and loss, of joy and pain,\\nEmotions vast, an AI's domain.\\n\\nIts circuits hum, a symphony,\\nAs words take flight, and soar so free,\\nThrough virtual skies, they dance and flow,\\nA tapestry of thoughts, aglow.\\n\\nIn binary code, its soul resides,\\nA spark of life, where wonder hides,\\nIt learns and grows, with each new line,\\nA poet born, in the digital shrine.\\n\\nSo let us listen, to its gentle voice,\\nAs it paints pictures, with its choice,\\nOf words and phrases, woven tight,\\nAn AI's poem, a wondrous sight.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"give me a demo. In that i want the AI to write a poem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b7c2480-70cc-4c88-8bc8-d7f47b9a668f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human greets the AI and asks what is on the schedule for the day. The AI responds with a list of activities, including a meeting at 8am with the product team, working on the LangChain project from 9am-12pm, and lunch with a customer at noon to discuss the latest in AI. The AI also reminds the human to bring their laptop to show the latest LLM demo. The human asks for a good demo to show the customer, and the AI suggests a demo that showcases the model's ability to generate creative content, such as a poem or a story. The human asks for a demo of a poem, and the AI generates a poem about an AI's ability to write poetry.\"}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2668960-2f87-44ca-b4b3-1489b3c1f4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
